{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from permanents import glynn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "n_sessions = 1 # number of sessions per iteration\n",
    "Learning_rate = 0.001 # learning rate, increase this to converge faster\n",
    "percentile = 95 # top 100-x percentile the agent will learn from\n",
    "super_percentile = 95 # top 100-x percentile of that survives to the next generation\n",
    "\n",
    "n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add 3 of the 5 free points present in all 312-avoiding matrices\n",
    "def add_free_points(input_state, n, step):\n",
    "    action_taken = torch.zeros([len(input_state)])\n",
    "    cur_state = torch.clone(input_state)\n",
    "\n",
    "    if step == 1:\n",
    "        action_index = 0\n",
    "    elif step == 2:\n",
    "        action_index = n**2-n\n",
    "    else:\n",
    "        action_index = n**2-1\n",
    "\n",
    "    cur_state[action_index] = 1\n",
    "    action_taken[action_index] = 1\n",
    "\n",
    "    return cur_state, action_taken    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a helper function that takes in a game and outputs the final board state\n",
    "def final_board_state(game):\n",
    "    n = len(game)\n",
    "    for i in range(len(game)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == n-1:\n",
    "            return game[i]\n",
    "        if game[i+1].sum() == 0 and game[i].sum() != 0:\n",
    "            return game[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add corners based on probability on the output of the corner_agent neural network\n",
    "def add_corner(input_state, action_vec, n, row_boundary, col_boundary):\n",
    "    corner_added = False\n",
    "    action_taken = torch.zeros([len(action_vec)])\n",
    "    cur_state = torch.clone(input_state)\n",
    "\n",
    "    terminal = False\n",
    "\n",
    "    while not corner_added:\n",
    "        action_index = torch.multinomial(action_vec, 1).item()\n",
    "        action_row = action_index//n\n",
    "        action_col = action_index%n\n",
    "\n",
    "        if (action_row == n-2 and action_col != n-1) or (action_col == 1 and action_row != 0):\n",
    "            action_vec[action_index] = 0\n",
    "            action_vec = action_vec / torch.sum(action_vec)\n",
    "        elif row_boundary <= action_row < n-1 and col_boundary <= action_col:\n",
    "            cur_state[action_index] = 1\n",
    "            action_taken[action_index] = 1\n",
    "            corner_added = True\n",
    "        else:\n",
    "            action_vec[action_index] = 0\n",
    "            action_vec = action_vec / torch.sum(action_vec)\n",
    "\n",
    "    if action_col == n-1:\n",
    "        terminal = True\n",
    "\n",
    "    return cur_state, action_taken, terminal, action_row, action_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a helper function to add point, action_vec is the output, output = agent(cur_state), agent = net\n",
    "def add_point(input_state, action_vec, forbidden_state, corners, n):\n",
    "    \n",
    "    ## add time\n",
    "    point_added = False\n",
    "    action_taken = torch.zeros([len(action_vec)])\n",
    "    cur_state = torch.clone(input_state)\n",
    "    cur_forbidden = torch.clone(forbidden_state)\n",
    "\n",
    "    while not point_added:\n",
    "        action_index = torch.multinomial(action_vec, 1).item()\n",
    "\n",
    "        if cur_state[action_index] == 0 and cur_forbidden[action_index] != 1:\n",
    "            # action\n",
    "            cur_state[action_index] = 1\n",
    "            action_taken[action_index] = 1\n",
    "            point_added = True\n",
    "\n",
    "            point_row = action_index//n\n",
    "            point_col = action_index%n\n",
    "            # fill forbidden\n",
    "            for corner in corners:\n",
    "                corner_row = corner//n\n",
    "                corner_col = corner%n\n",
    "                # fill left block\n",
    "                if corner_row < point_row and point_col < corner_col:\n",
    "                    for forbidden_row in range(corner_row+1, point_row):\n",
    "                        for forbidden_col in range(point_col):\n",
    "                            forbidden_index = forbidden_row*n + forbidden_col\n",
    "                            if cur_state[forbidden_index] == 0:\n",
    "                                cur_forbidden[forbidden_index] = 1\n",
    "                    # fill right block\n",
    "                    for forbidden_col in range(point_col+1, corner_col):\n",
    "                        for forbidden_row in range(point_row+1, n):\n",
    "                            forbidden_index = forbidden_row*n + forbidden_col\n",
    "                            if cur_state[forbidden_index] == 0:\n",
    "                                cur_forbidden[forbidden_index] = 1\n",
    "        else:\n",
    "            action_vec[action_index] = 0\n",
    "            action_vec = action_vec / torch.sum(action_vec)\n",
    "\n",
    "    return cur_state, action_taken, cur_forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, corner_agent, n_sessions, n):\n",
    "    # (nth session, always 4*n - 4 steps, always n*n board)\n",
    "    states = torch.zeros((n_sessions, 4*n-4+1, n*n))\n",
    "    actions = torch.zeros((n_sessions, 4*n-4+1, n*n))\n",
    "    forbidden_points = torch.zeros((n_sessions, 4*n-4+1, n*n))\n",
    "    corners = torch.zeros((n_sessions, 4*n-4+1, n*n))\n",
    "\n",
    "    scores = torch.zeros([n_sessions])\n",
    "    states.to(device)\n",
    "\n",
    "    for i in range(n_sessions):\n",
    "        step = 0\n",
    "\n",
    "        while step < 3:\n",
    "            step += 1\n",
    "            cur_state = states[i,step-1, :]\n",
    "\n",
    "            new_state, action = add_free_points(cur_state, n, step)\n",
    "            \n",
    "            actions[i,step-1, :] = action\n",
    "            states[i,step, :] = new_state\n",
    "\n",
    "        # add corners\n",
    "        corner_num = 0\n",
    "        corner_list = [0]*(n-2) # there can be at most n-2 corners\n",
    "\n",
    "        row_boundary, col_boundary = 0, 1\n",
    "\n",
    "        row_zero_set = False\n",
    "        terminal = False\n",
    "        while not terminal:\n",
    "            step += 1\n",
    "            cur_state = states[i,step-1, :]\n",
    "\n",
    "            output = corner_agent(cur_state)\n",
    "\n",
    "            new_state, action, terminal, row_added, col_added = add_corner(cur_state, output, n, row_boundary, col_boundary)\n",
    "            \n",
    "            # Ensures that a corner is always set in first row. If the lower block is entered, essentially sets (1,2), 1-indexed, as the first corner\n",
    "            # then artifically using the above point as the next step. The lower black can only be entered once.\n",
    "            if row_added == 0:\n",
    "                row_zero_set = True\n",
    "            if not row_zero_set:\n",
    "                cur_state = torch.clone(states[i,step-1, :])\n",
    "                cur_state[1] = 1\n",
    "\n",
    "                actions[i,step-1, 1] = 1\n",
    "                states[i,step, :] = cur_state\n",
    "                corners[i,step, 1] = 1\n",
    "            \n",
    "                corner_list[corner_num] = 1 # the first corner is at index 1\n",
    "                corner_num += 1\n",
    "            \n",
    "                step += 1\n",
    "                row_zero_set = True\n",
    "\n",
    "                new_state[1] = 1\n",
    "            ''' need to account for attempted corners in second column, other than index 1 '''\n",
    "            corner_index = row_added*n + col_added\n",
    "            corner_list[corner_num] = corner_index\n",
    "            corners[i,step, corner_index] = 1\n",
    "\n",
    "            corner_num += 1\n",
    "\n",
    "            row_boundary = row_added + 1\n",
    "            col_boundary = col_added + 1\n",
    "\n",
    "            actions[i,step-1, :] = action\n",
    "            states[i,step, :] = new_state\n",
    "\n",
    "        # prune corner list\n",
    "        corner_list = corner_list[:corner_num]\n",
    "        corner_list.sort()\n",
    "\n",
    "        # add induced corners\n",
    "        for corner_index in corner_list:\n",
    "            step += 1\n",
    "            cur_state = torch.clone(states[i,step-1, :])\n",
    "            #cur_forbidden = torch.clone(forbidden_points[i,step-1, :])\n",
    "\n",
    "            corner_row = corner_index//n\n",
    "            corner_col = corner_index%n\n",
    "            # induced corner = (i+1, j-1) -> (i+1)n + (j-1), where i=row and j=col\n",
    "            induced_corner_index = (corner_row+1)*n + (corner_col-1)\n",
    "            cur_state[induced_corner_index] = 1\n",
    "\n",
    "            actions[i,step-1, induced_corner_index] = 1\n",
    "            states[i,step, :] = cur_state\n",
    "\n",
    "        # add zig-zag and upper forbidden points\n",
    "        corner_list.append(n**2-1) # n^2-1 is not a corner, but we append it to work with while-loop below\n",
    "        #corner_list.append(float('inf'))\n",
    "        cur_path_element = 1 # first element on the zig-zag path, besides upper-left corner\n",
    "        target_corner_num = 0\n",
    "        target_corner = corner_list[target_corner_num]\n",
    "\n",
    "        # first row\n",
    "        while cur_path_element != target_corner:\n",
    "            # action\n",
    "            step += 1\n",
    "            cur_state = torch.clone(states[i,step-1, :])\n",
    "            cur_state[cur_path_element] = 1\n",
    "\n",
    "            actions[i,step-1, cur_path_element] = 1\n",
    "            states[i,step, :] = cur_state\n",
    "\n",
    "            cur_path_element += 1 # step element by one row, fixing column\n",
    "\n",
    "        # update forbidden states\n",
    "        cur_forbidden_state = torch.clone(forbidden_points[i,step-1, :])\n",
    "        for forbidden_index in range(cur_path_element+1, n):\n",
    "            cur_forbidden_state[forbidden_index] = 1 \n",
    "        forbidden_points[i, step, :] = cur_forbidden_state\n",
    "\n",
    "        target_corner_num += 1\n",
    "        while target_corner_num < len(corner_list):  #cur_path_element < n**2-n-1:\n",
    "            target_corner = corner_list[target_corner_num]  \n",
    "            target_row = target_corner//n\n",
    "            #target_col = target_corner%n\n",
    "\n",
    "            cur_row = cur_path_element//n\n",
    "            cur_col = cur_path_element%n\n",
    "\n",
    "            while cur_path_element != target_corner and cur_path_element != n**2-n-1: # incorrect row OR incorrect column\n",
    "                if cur_row != target_row: # must move row\n",
    "                    step += 1\n",
    "                    # update forbidden states\n",
    "                    cur_forbidden_state = torch.clone(forbidden_points[i,step-1, :])\n",
    "                    for forbidden_index in range(cur_path_element+1, cur_row*n + n):\n",
    "                        cur_forbidden_state[forbidden_index] = 1 \n",
    "                    forbidden_points[i, step, :] = cur_forbidden_state\n",
    "                    # action\n",
    "                    cur_state = torch.clone(states[i,step-1, :])\n",
    "                    cur_path_element += n # step element by one row, fixing column\n",
    "                    cur_state[cur_path_element] = 1\n",
    "\n",
    "                    actions[i,step-1, cur_path_element] = 1\n",
    "                    states[i,step, :] = cur_state\n",
    "\n",
    "                    cur_row += 1\n",
    "                else: # cur_col != target_col, i.e, correct row but must move column\n",
    "                    cur_path_element += 1\n",
    "                    if cur_path_element != target_corner:\n",
    "                        # action\n",
    "                        step += 1\n",
    "\n",
    "                        cur_forbidden_state = torch.clone(forbidden_points[i,step-1, :])\n",
    "                        forbidden_points[i, step, :] = cur_forbidden_state\n",
    "\n",
    "                        cur_state = torch.clone(states[i,step-1, :])\n",
    "                        #cur_path_element += 1 # step element by one column, fixing row\n",
    "                        cur_state[cur_path_element] = 1\n",
    "\n",
    "                        actions[i,step-1, cur_path_element] = 1\n",
    "                        states[i,step, :] = cur_state\n",
    "\n",
    "                        cur_col += 1\n",
    "            target_corner_num += 1\n",
    "            #target_corner = corner_list[target_corner_num]\n",
    "\n",
    "        # add remaining points\n",
    "        terminal = False\n",
    "        while step < 4*n - 4: #4*n - 4:\n",
    "            step+=1\n",
    "            cur_state = states[i,step-1, :]\n",
    "            cur_forbidden = forbidden_points[i,step-1, :]\n",
    "\n",
    "            #tic = time.time()\n",
    "            #output = agent(cur_state)\n",
    "            #pred_time += time.time() - tic\n",
    "\n",
    "            output = agent(cur_state)\n",
    "\n",
    "            #tic = time.time()\n",
    "            new_state, action, new_forbidden_state = add_point(cur_state, output, cur_forbidden, corner_list, n)\n",
    "            #play_time += time.time() - tic\n",
    "\n",
    "            #tic = time.time()\n",
    "            #if terminal:\n",
    "            #    total_score[i] = cur_state.sum()\n",
    "            #    continue\n",
    "            actions[i,step-1, :] = action\n",
    "            #scoreUpdate_time += time.time() - tic\n",
    "\n",
    "            #tic = time.time()\n",
    "            states[i,step, :] = new_state\n",
    "            #recordsess_time += time.time() - tic\n",
    "\n",
    "            forbidden_points[i,step, :] = new_forbidden_state\n",
    "        final_state = states[i,step, :]\n",
    "        state_mtx = final_state.reshape(n,n)\n",
    "        scores[i] = glynn(state_mtx.numpy())\n",
    "\n",
    "    return states, actions, scores # forbidden_points, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_super_sessions(states_batch, actions_batch, rewards_batch, percentile=90):\n",
    "\n",
    "    counter = n_sessions * (100 - percentile)/100\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    super_states = torch.empty(0)\n",
    "    super_actions = torch.empty(0)\n",
    "    #super_forbidden = torch.empty(0)\n",
    "    super_rewards = torch.empty(0)\n",
    "\n",
    "    for i in range(len(states_batch)):\n",
    "\n",
    "        if counter <= 0:\n",
    "            break\n",
    "\n",
    "        if rewards_batch[i] >= reward_threshold - 0.001:\n",
    "            super_states = torch.cat((super_states, states_batch[i].unsqueeze(0)), dim=0)\n",
    "            super_actions = torch.cat((super_actions, actions_batch[i].unsqueeze(0)), dim=0)\n",
    "            #super_forbidden = torch.cat((super_forbidden, forbidden_batch[i].unsqueeze(0)), dim=0)\n",
    "            super_rewards = torch.cat((super_rewards, torch.tensor([rewards_batch[i]])), dim=0)\n",
    "            counter -= 1\n",
    "\n",
    "\n",
    "    return super_states, super_actions, super_rewards #super_forbidden, super_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "\n",
    "    counter = n_sessions * (100 - percentile)/100\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    elite_states = torch.empty(0)\n",
    "    elite_actions = torch.empty(0)\n",
    "\n",
    "    for i in range(len(states_batch)):\n",
    "\n",
    "        if counter <= 0:\n",
    "            break\n",
    "\n",
    "        if rewards_batch[i] >= reward_threshold - 0.01:\n",
    "            game_end_index = 0\n",
    "            for item in states_batch[i]:\n",
    "                if item.sum() == 0 and game_end_index != 0:\n",
    "                    break\n",
    "                elite_states = torch.cat((elite_states, item.unsqueeze(0)))\n",
    "                game_end_index += 1\n",
    "\n",
    "            for item in actions_batch[i]:\n",
    "                if game_end_index == 0:\n",
    "                    break\n",
    "                elite_actions = torch.cat((elite_actions, item.unsqueeze(0)))\n",
    "                game_end_index -= 1\n",
    "            counter -= 1\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 12.])\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states, actions, scores = generate_session(best_net, best_corner_net, 1, n) #  forbidden_points,\n",
    "\n",
    "# Plot\n",
    "step_through = step\n",
    "state = states[0,step_through,:]\n",
    "state_mtx = state.reshape(n,n)\n",
    "\n",
    "action = actions[0,step_through-1,:]\n",
    "action_mtx = action.reshape(n,n)\n",
    "\n",
    "#forbidden = forbidden_points[0,step_through,:]\n",
    "#forbidden_mtx = forbidden.reshape(n,n)\n",
    "\n",
    "plot_board(state_mtx)\n",
    "#plot_board(action_mtx)\n",
    "#plot_board(forbidden_mtx)\n",
    "\n",
    "print(glynn(state_mtx.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0. Best individuals: [56. 42. 40. 32. 32.]\n",
      "Mean best reward: tensor(40.4000)\n",
      "\n",
      "1. Best individuals: [56. 44. 42. 42. 40.]\n",
      "Mean best reward: tensor(44.8000)\n",
      "\n",
      "2. Best individuals: [56. 56. 52. 44. 42.]\n",
      "Mean best reward: tensor(50.)\n",
      "\n",
      "3. Best individuals: [66. 56. 56. 48. 44.]\n",
      "Mean best reward: tensor(54.)\n",
      "\n",
      "4. Best individuals: [88. 66. 56. 56. 48.]\n",
      "Mean best reward: tensor(62.8000)\n",
      "\n",
      "5. Best individuals: [88. 84. 66. 62. 56.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "6. Best individuals: [88. 84. 66. 62. 40.]\n",
      "Mean best reward: tensor(68.)\n",
      "\n",
      "7. Best individuals: [88. 84. 66. 62. 56.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "8. Best individuals: [88. 84. 66. 62. 50.]\n",
      "Mean best reward: tensor(70.)\n",
      "\n",
      "9. Best individuals: [88. 84. 70. 66. 62.]\n",
      "Mean best reward: tensor(74.)\n",
      "\n",
      "10. Best individuals: [88. 84. 70. 66. 48.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "11. Best individuals: [88. 84. 70. 60. 52.]\n",
      "Mean best reward: tensor(70.8000)\n",
      "\n",
      "12. Best individuals: [88. 84. 70. 56. 56.]\n",
      "Mean best reward: tensor(70.8000)\n",
      "\n",
      "13. Best individuals: [88. 84. 70. 64. 56.]\n",
      "Mean best reward: tensor(72.4000)\n",
      "\n",
      "14. Best individuals: [88. 84. 70. 64. 48.]\n",
      "Mean best reward: tensor(70.8000)\n",
      "\n",
      "15. Best individuals: [88. 84. 58. 48. 48.]\n",
      "Mean best reward: tensor(65.2000)\n",
      "\n",
      "16. Best individuals: [88. 84. 58. 48. 32.]\n",
      "Mean best reward: tensor(62.)\n",
      "\n",
      "17. Best individuals: [88. 84. 76. 60. 48.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "18. Best individuals: [88. 84. 76. 68. 52.]\n",
      "Mean best reward: tensor(73.6000)\n",
      "\n",
      "19. Best individuals: [88. 84. 82. 76. 60.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "20. Best individuals: [88. 84. 82. 76. 60.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "21. Best individuals: [88. 84. 82. 76. 60.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "22. Best individuals: [88. 84. 82. 76. 66.]\n",
      "Mean best reward: tensor(79.2000)\n",
      "\n",
      "23. Best individuals: [88. 84. 82. 76. 60.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "24. Best individuals: [88. 84. 82. 74. 72.]\n",
      "Mean best reward: tensor(80.)\n",
      "\n",
      "25. Best individuals: [88. 84. 82. 74. 64.]\n",
      "Mean best reward: tensor(78.4000)\n",
      "\n",
      "26. Best individuals: [88. 84. 82. 74. 62.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "27. Best individuals: [88. 84. 82. 74. 56.]\n",
      "Mean best reward: tensor(76.8000)\n",
      "\n",
      "28. Best individuals: [88. 84. 82. 80. 72.]\n",
      "Mean best reward: tensor(81.2000)\n",
      "\n",
      "29. Best individuals: [92. 88. 84. 82. 80.]\n",
      "Mean best reward: tensor(85.2000)\n",
      "\n",
      "30. Best individuals: [92. 88. 84. 36. 36.]\n",
      "Mean best reward: tensor(67.2000)\n",
      "\n",
      "31. Best individuals: [92. 52. 42. 36. 36.]\n",
      "Mean best reward: tensor(51.6000)\n",
      "\n",
      "32. Best individuals: [92. 78. 64. 52. 42.]\n",
      "Mean best reward: tensor(65.6000)\n",
      "\n",
      "33. Best individuals: [92. 78. 64. 58. 54.]\n",
      "Mean best reward: tensor(69.2000)\n",
      "\n",
      "34. Best individuals: [92. 78. 64. 58. 48.]\n",
      "Mean best reward: tensor(68.)\n",
      "\n",
      "35. Best individuals: [92. 78. 64. 60. 48.]\n",
      "Mean best reward: tensor(68.4000)\n",
      "\n",
      "36. Best individuals: [92. 78. 78. 68. 64.]\n",
      "Mean best reward: tensor(76.)\n",
      "\n",
      "37. Best individuals: [92. 78. 78. 68. 44.]\n",
      "Mean best reward: tensor(72.)\n",
      "\n",
      "38. Best individuals: [92. 78. 78. 68. 41.]\n",
      "Mean best reward: tensor(71.4000)\n",
      "\n",
      "39. Best individuals: [92. 78. 78. 60. 52.]\n",
      "Mean best reward: tensor(72.)\n",
      "\n",
      "40. Best individuals: [92. 78. 78. 68. 60.]\n",
      "Mean best reward: tensor(75.2000)\n",
      "\n",
      "41. Best individuals: [92. 78. 78. 68. 48.]\n",
      "Mean best reward: tensor(72.8000)\n",
      "\n",
      "42. Best individuals: [92. 78. 78. 72. 56.]\n",
      "Mean best reward: tensor(75.2000)\n",
      "\n",
      "43. Best individuals: [92. 78. 78. 72. 56.]\n",
      "Mean best reward: tensor(75.2000)\n",
      "\n",
      "44. Best individuals: [92. 78. 78. 72. 56.]\n",
      "Mean best reward: tensor(75.2000)\n",
      "\n",
      "45. Best individuals: [92. 78. 78. 72. 48.]\n",
      "Mean best reward: tensor(73.6000)\n",
      "\n",
      "46. Best individuals: [92. 78. 78. 59. 56.]\n",
      "Mean best reward: tensor(72.6000)\n",
      "\n",
      "47. Best individuals: [92. 78. 78. 59. 58.]\n",
      "Mean best reward: tensor(73.)\n",
      "\n",
      "48. Best individuals: [92. 82. 78. 78. 64.]\n",
      "Mean best reward: tensor(78.8000)\n",
      "\n",
      "49. Best individuals: [92. 82. 78. 78. 28.]\n",
      "Mean best reward: tensor(71.6000)\n",
      "\n",
      "50. Best individuals: [92. 82. 78. 58. 46.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "51. Best individuals: [92. 84. 82. 78. 60.]\n",
      "Mean best reward: tensor(79.2000)\n",
      "\n",
      "52. Best individuals: [92. 84. 82. 78. 56.]\n",
      "Mean best reward: tensor(78.4000)\n",
      "\n",
      "53. Best individuals: [92. 84. 84. 82. 56.]\n",
      "Mean best reward: tensor(79.6000)\n",
      "\n",
      "54. Best individuals: [92. 84. 84. 70. 60.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "55. Best individuals: [92. 84. 84. 70. 58.]\n",
      "Mean best reward: tensor(77.6000)\n",
      "\n",
      "56. Best individuals: [92. 84. 84. 70. 48.]\n",
      "Mean best reward: tensor(75.6000)\n",
      "\n",
      "57. Best individuals: [92. 84. 84. 70. 57.]\n",
      "Mean best reward: tensor(77.4000)\n",
      "\n",
      "58. Best individuals: [92. 84. 84. 48. 48.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "59. Best individuals: [92. 84. 56. 48. 48.]\n",
      "Mean best reward: tensor(65.6000)\n",
      "\n",
      "60. Best individuals: [92. 84. 63. 48. 48.]\n",
      "Mean best reward: tensor(67.)\n",
      "\n",
      "61. Best individuals: [92. 84. 64. 63. 48.]\n",
      "Mean best reward: tensor(70.2000)\n",
      "\n",
      "62. Best individuals: [92. 84. 66. 64. 63.]\n",
      "Mean best reward: tensor(73.8000)\n",
      "\n",
      "63. Best individuals: [92. 84. 66. 64. 60.]\n",
      "Mean best reward: tensor(73.2000)\n",
      "\n",
      "64. Best individuals: [92. 84. 66. 64. 36.]\n",
      "Mean best reward: tensor(68.4000)\n",
      "\n",
      "65. Best individuals: [92. 84. 66. 50. 46.]\n",
      "Mean best reward: tensor(67.6000)\n",
      "\n",
      "66. Best individuals: [92. 84. 53. 52. 52.]\n",
      "Mean best reward: tensor(66.6000)\n",
      "\n",
      "67. Best individuals: [92. 84. 53. 52. 46.]\n",
      "Mean best reward: tensor(65.4000)\n",
      "\n",
      "68. Best individuals: [92. 84. 56. 53. 52.]\n",
      "Mean best reward: tensor(67.4000)\n",
      "\n",
      "69. Best individuals: [92. 84. 72. 56. 52.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "70. Best individuals: [92. 84. 64. 64. 64.]\n",
      "Mean best reward: tensor(73.6000)\n",
      "\n",
      "71. Best individuals: [92. 84. 76. 64. 64.]\n",
      "Mean best reward: tensor(76.)\n",
      "\n",
      "72. Best individuals: [92. 84. 76. 64. 40.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "73. Best individuals: [92. 84. 76. 64. 52.]\n",
      "Mean best reward: tensor(73.6000)\n",
      "\n",
      "74. Best individuals: [92. 84. 76. 68. 64.]\n",
      "Mean best reward: tensor(76.8000)\n",
      "\n",
      "75. Best individuals: [92. 84. 82. 76. 72.]\n",
      "Mean best reward: tensor(81.2000)\n",
      "\n",
      "76. Best individuals: [92. 84. 82. 76. 62.]\n",
      "Mean best reward: tensor(79.2000)\n",
      "\n",
      "77. Best individuals: [92. 84. 82. 76. 70.]\n",
      "Mean best reward: tensor(80.8000)\n",
      "\n",
      "78. Best individuals: [92. 84. 82. 76. 64.]\n",
      "Mean best reward: tensor(79.6000)\n",
      "\n",
      "79. Best individuals: [92. 84. 82. 76. 62.]\n",
      "Mean best reward: tensor(79.2000)\n",
      "\n",
      "80. Best individuals: [92. 84. 82. 76. 52.]\n",
      "Mean best reward: tensor(77.2000)\n",
      "\n",
      "81. Best individuals: [92. 84. 82. 76. 56.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "82. Best individuals: [92. 84. 82. 76. 64.]\n",
      "Mean best reward: tensor(79.6000)\n",
      "\n",
      "83. Best individuals: [92. 84. 82. 76. 44.]\n",
      "Mean best reward: tensor(75.6000)\n",
      "\n",
      "84. Best individuals: [92. 84. 82. 56. 48.]\n",
      "Mean best reward: tensor(72.4000)\n",
      "\n",
      "85. Best individuals: [92. 84. 82. 64. 52.]\n",
      "Mean best reward: tensor(74.8000)\n",
      "\n",
      "86. Best individuals: [92. 84. 82. 64. 52.]\n",
      "Mean best reward: tensor(74.8000)\n",
      "\n",
      "87. Best individuals: [92. 84. 82. 80. 78.]\n",
      "Mean best reward: tensor(83.2000)\n",
      "\n",
      "88. Best individuals: [92. 84. 82. 56. 56.]\n",
      "Mean best reward: tensor(74.)\n",
      "\n",
      "89. Best individuals: [92. 84. 82. 56. 44.]\n",
      "Mean best reward: tensor(71.6000)\n",
      "\n",
      "90. Best individuals: [92. 84. 82. 64. 64.]\n",
      "Mean best reward: tensor(77.2000)\n",
      "\n",
      "91. Best individuals: [92. 84. 82. 68. 64.]\n",
      "Mean best reward: tensor(78.)\n",
      "\n",
      "92. Best individuals: [92. 84. 82. 68. 66.]\n",
      "Mean best reward: tensor(78.4000)\n",
      "\n",
      "93. Best individuals: [92. 84. 82. 68. 40.]\n",
      "Mean best reward: tensor(73.2000)\n",
      "\n",
      "94. Best individuals: [92. 84. 82. 54. 44.]\n",
      "Mean best reward: tensor(71.2000)\n",
      "\n",
      "95. Best individuals: [92. 84. 80. 72. 60.]\n",
      "Mean best reward: tensor(77.6000)\n",
      "\n",
      "96. Best individuals: [92. 84. 80. 64. 61.]\n",
      "Mean best reward: tensor(76.2000)\n",
      "\n",
      "97. Best individuals: [92. 84. 80. 64. 60.]\n",
      "Mean best reward: tensor(76.)\n",
      "\n",
      "98. Best individuals: [104.  92.  84.  80.  64.]\n",
      "Mean best reward: tensor(84.8000)\n",
      "\n",
      "99. Best individuals: [104.  92.  84.  66.  64.]\n",
      "Mean best reward: tensor(82.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # Make a new folder if \\'Data\\' folder does not exist\\n    if not os.path.exists(\\'Data\\'):\\n        os.makedirs(\\'Data\\')\\n\\n    max_index = torch.argmax(super_rewards)\\n\\n    if super_rewards[max_index] > cur_best_reward:\\n        cur_best_reward = super_rewards[max_index]\\n        cur_best_board = final_board_state(super_states[max_index]).numpy()\\n        cur_best_game = super_states[max_index]\\n        cur_best_actions = super_actions[max_index]\\n\\n        best_states_set = set()\\n        best_states_set.add(str(cur_best_board))\\n\\n        with open(os.path.join(\\'Data\\', str(filename)+\\'_best_board_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n            f.write(str(convert_to_board(cur_best_board, n))) #, construction)))\\n            f.write(\"\\n\")\\n        \\n        with open(os.path.join(\\'Data\\', str(filename)+\\'_best_reward_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n            f.write(str(cur_best_reward))\\n            f.write(\"\\n\")\\n        \\n        counter = 0\\n    \\n    if super_rewards[max_index] == cur_best_reward:\\n        counter += 1\\n\\n        cur_best_board = final_board_state(super_states[max_index]).numpy()\\n        if str(cur_best_board) not in best_states_set:\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_board_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(convert_to_board(cur_best_board, n))) #, construction)))\\n                f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_reward_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(cur_best_reward))\\n                f.write(\"\\n\")\\n    \\n    #if board_type == \"line\" and cur_best_reward == 4*n:\\n    #    return net\\n    \\n    #if counter > 1000:\\n    #    return net\\n\\n    if write_all:\\n        if (i%20 == 1): #Write all important info to files every 20 iterations\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species\\'+\\'.txt\\'), \\'w\\') as f:\\n                for game in super_states:\\n                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #, construction)))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_rewards\\'+\\'.txt\\'), \\'w\\') as f:\\n                for item in super_rewards:\\n                    f.write(str(item))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_100_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_all_reward)+\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_super_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_best_reward)+\"\\n\")\\n            if (i%200==2):\\n                with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\\n                    f.write(\"\\n\")\\n    if write_best:\\n        if mean_best_reward > pass_threshold:\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species\\'+\\'.txt\\'), \\'w\\') as f:\\n                for game in super_states:\\n                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #,construction)))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_rewards\\'+\\'.txt\\'), \\'w\\') as f:\\n                for item in super_rewards:\\n                    f.write(str(item))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_100_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_all_reward)+\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_super_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_best_reward)+\"\\n\")\\n            if (i%200==2):\\n                max_index = torch.argmax(super_rewards)\\n                with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\\n                    f.write(\"\\n\")\\n\\n    if counter > 1000:\\n        if mean_best_reward > pass_threshold:\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species\\'+\\'.txt\\'), \\'w\\') as f:\\n                for game in super_states:\\n                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #, construction)))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_rewards\\'+\\'.txt\\'), \\'w\\') as f:\\n                for item in super_rewards:\\n                    f.write(str(item))\\n                    f.write(\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_100_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_all_reward)+\"\\n\")\\n            with open(os.path.join(\\'Data\\', str(filename)+\\'_best_super_rewards\\'+\\'.txt\\'), \\'a\\') as f:\\n                f.write(str(mean_best_reward)+\"\\n\")\\n            if (i%200==2):\\n                max_index = torch.argmax(super_rewards)\\n                with open(os.path.join(\\'Data\\', str(filename)+\\'_best_species_timeline\\'+\\'.txt\\'), \\'a\\') as f:\\n                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\\n                    f.write(\"\\n\")\\n#        return net\\n'"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sessions = 100 # number of sessions per iteration\n",
    "Learning_rate = 0.001 # learning rate, increase this to converge faster\n",
    "\n",
    "filename = \"test_output\"\n",
    "n = 8\n",
    "\n",
    "input_space = n*n\n",
    "INF = 1000000\n",
    "\n",
    "first_layer_neurons = 128\n",
    "second_layer_neurons = 64\n",
    "third_layer_neurons = 4\n",
    "last_layer_neurons = n*n\n",
    "\n",
    "# Defining the neural network architecture\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_space, first_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_layer_neurons, second_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_layer_neurons, third_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(third_layer_neurons, last_layer_neurons)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create neural network for corners\n",
    "corner_agent = MyNet()\n",
    "\n",
    "# Create neural network for all other points\n",
    "agent = MyNet()\n",
    "\n",
    "# Definte the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "corner_optimizer = optim.SGD(corner_agent.parameters(), lr=Learning_rate)\n",
    "optimizer = optim.SGD(agent.parameters(), lr=Learning_rate)\n",
    "\n",
    "global super_states\n",
    "super_states = torch.empty((0, n*n, n*n), dtype=torch.int)\n",
    "#global super_forbidden\n",
    "#super_forbidden = torch.empty((0, n*n, n*n), dtype=torch.int)\n",
    "global super_actions\n",
    "super_actions = torch.tensor([], dtype=torch.int)\n",
    "global super_rewards\n",
    "super_rewards = torch.tensor([])\n",
    "\n",
    "counter = 0\n",
    "pass_threshold = 1.25 * n\n",
    "\n",
    "cur_best_reward = 0\n",
    "cur_best_board = torch.zeros([n*n])\n",
    "cur_best_game = torch.zeros([n*n, n*n])\n",
    "cur_best_actions = torch.zeros([n*n, n*n])\n",
    "\n",
    "for i in range(100):\n",
    "    states_batch, actions_batch, rewards_batch = generate_session(agent, corner_agent, n_sessions, n) # forbidden_batch\n",
    "\n",
    "#    states_batch = states_batch.to(dtype=torch.to)\n",
    "\n",
    "    if i > 0:\n",
    "        states_batch = torch.cat((states_batch, super_states), dim=0)\n",
    "        actions_batch = torch.cat((actions_batch, super_actions), dim=0)\n",
    "        #fobidden_batch = torch.cat((forbidden_batch, super_forbidden), dim=0)\n",
    "        rewards_batch = torch.cat((torch.tensor([cur_best_reward]), rewards_batch, super_rewards), dim=0)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile = percentile)\n",
    "\n",
    "    super_sessions = select_super_sessions(states_batch, actions_batch, rewards_batch, percentile = super_percentile)\n",
    "\n",
    "\n",
    "    super_sessions = [(super_sessions[0][i], super_sessions[1][i], super_sessions[2][i]) for i in range(len(super_sessions[2]))] #, super_sessions[3][i]\n",
    "    super_sessions.sort(key=lambda x: x[2], reverse=True)\n",
    "   \n",
    "    elite_states.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = agent(elite_states)\n",
    "    loss = criterion(outputs, elite_actions.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    corner_optimizer.zero_grad()\n",
    "    outputs = corner_agent(elite_states)\n",
    "    loss = criterion(outputs, elite_actions.float())\n",
    "    loss.backward()\n",
    "    corner_optimizer.step()\n",
    "\n",
    "    super_states = torch.stack([super_sessions[i][0] for i in range(len(super_sessions))])\n",
    "    super_actions = torch.stack([super_sessions[i][1] for i in range(len(super_sessions))])\n",
    "    #super_forbidden = torch.stack([super_sessions[i][2] for i in range(len(super_sessions))])\n",
    "    super_rewards = torch.stack([super_sessions[i][2] for i in range(len(super_sessions))])\n",
    "\n",
    "    ########\n",
    "\n",
    "    mean_all_reward = torch.mean(rewards_batch[-100:])\n",
    "    mean_best_reward = torch.mean(super_rewards)\n",
    "\n",
    "    #acceptence_threshold = mean_all_reward - 1\n",
    "    #explore_rate = 1-(i/10000)\n",
    "\n",
    "    #if mean_best_reward > 1.25*n:\n",
    "    #    counter+=1\n",
    "\n",
    "    print(\"\\n\" + str(i) +  \". Best individuals: \" + str(np.flip(np.sort(super_rewards))))\n",
    "\n",
    "    #uncomment below line to print out how much time each step in this loop takes.\n",
    "    #print(\t\"Mean reward: \" + str(mean_all_reward) + \"\\nSessgen: \" + str(sessgen_time) + \", other: \" + str(randomcomp_time) + \", select1: \" + str(select1_time) + \", select2: \" + str(select2_time) + \", select3: \" + str(select3_time) +  \", fit: \" + str(fit_time) + \", score: \" + str(score_time))\n",
    "\n",
    "    #uncomment below line to print out the mean best reward\n",
    "    print(\"Mean best reward: \" + str(mean_best_reward))\n",
    "'''\n",
    "    # Make a new folder if 'Data' folder does not exist\n",
    "    if not os.path.exists('Data'):\n",
    "        os.makedirs('Data')\n",
    "\n",
    "    max_index = torch.argmax(super_rewards)\n",
    "\n",
    "    if super_rewards[max_index] > cur_best_reward:\n",
    "        cur_best_reward = super_rewards[max_index]\n",
    "        cur_best_board = final_board_state(super_states[max_index]).numpy()\n",
    "        cur_best_game = super_states[max_index]\n",
    "        cur_best_actions = super_actions[max_index]\n",
    "\n",
    "        best_states_set = set()\n",
    "        best_states_set.add(str(cur_best_board))\n",
    "\n",
    "        with open(os.path.join('Data', str(filename)+'_best_board_timeline'+'.txt'), 'a') as f:\n",
    "            f.write(str(convert_to_board(cur_best_board, n))) #, construction)))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        with open(os.path.join('Data', str(filename)+'_best_reward_timeline'+'.txt'), 'a') as f:\n",
    "            f.write(str(cur_best_reward))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        counter = 0\n",
    "    \n",
    "    if super_rewards[max_index] == cur_best_reward:\n",
    "        counter += 1\n",
    "\n",
    "        cur_best_board = final_board_state(super_states[max_index]).numpy()\n",
    "        if str(cur_best_board) not in best_states_set:\n",
    "            with open(os.path.join('Data', str(filename)+'_best_board_timeline'+'.txt'), 'a') as f:\n",
    "                f.write(str(convert_to_board(cur_best_board, n))) #, construction)))\n",
    "                f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_reward_timeline'+'.txt'), 'a') as f:\n",
    "                f.write(str(cur_best_reward))\n",
    "                f.write(\"\\n\")\n",
    "    \n",
    "    #if board_type == \"line\" and cur_best_reward == 4*n:\n",
    "    #    return net\n",
    "    \n",
    "    #if counter > 1000:\n",
    "    #    return net\n",
    "\n",
    "    if write_all:\n",
    "        if (i%20 == 1): #Write all important info to files every 20 iterations\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species'+'.txt'), 'w') as f:\n",
    "                for game in super_states:\n",
    "                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #, construction)))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species_rewards'+'.txt'), 'w') as f:\n",
    "                for item in super_rewards:\n",
    "                    f.write(str(item))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_100_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_all_reward)+\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_super_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_best_reward)+\"\\n\")\n",
    "            if (i%200==2):\n",
    "                with open(os.path.join('Data', str(filename)+'_best_species_timeline'+'.txt'), 'a') as f:\n",
    "                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\n",
    "                    f.write(\"\\n\")\n",
    "    if write_best:\n",
    "        if mean_best_reward > pass_threshold:\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species'+'.txt'), 'w') as f:\n",
    "                for game in super_states:\n",
    "                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #,construction)))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species_rewards'+'.txt'), 'w') as f:\n",
    "                for item in super_rewards:\n",
    "                    f.write(str(item))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_100_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_all_reward)+\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_super_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_best_reward)+\"\\n\")\n",
    "            if (i%200==2):\n",
    "                max_index = torch.argmax(super_rewards)\n",
    "                with open(os.path.join('Data', str(filename)+'_best_species_timeline'+'.txt'), 'a') as f:\n",
    "                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "    if counter > 1000:\n",
    "        if mean_best_reward > pass_threshold:\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species'+'.txt'), 'w') as f:\n",
    "                for game in super_states:\n",
    "                    f.write(str(convert_to_board(final_board_state(game).numpy(), n))) #, construction)))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_species_rewards'+'.txt'), 'w') as f:\n",
    "                for item in super_rewards:\n",
    "                    f.write(str(item))\n",
    "                    f.write(\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_100_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_all_reward)+\"\\n\")\n",
    "            with open(os.path.join('Data', str(filename)+'_best_super_rewards'+'.txt'), 'a') as f:\n",
    "                f.write(str(mean_best_reward)+\"\\n\")\n",
    "            if (i%200==2):\n",
    "                max_index = torch.argmax(super_rewards)\n",
    "                with open(os.path.join('Data', str(filename)+'_best_species_timeline'+'.txt'), 'a') as f:\n",
    "                    f.write(str(convert_to_board(final_board_state(super_states[max_index]).numpy(), n))) #, construction)))\n",
    "                    f.write(\"\\n\")\n",
    "#        return net\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_corner_net = corner_agent\n",
    "best_net = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_all = False\n",
    "write_best = True\n",
    "filename = \"test_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 23, 63]\n",
      "4\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(corner_list)\n",
    "print(target_corner_num)\n",
    "print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "step_through = step\n",
    "state = states[0,step_through,:]\n",
    "state_mtx = state.reshape(n,n)\n",
    "\n",
    "#action = actions[0,step_through-1,:]\n",
    "#action_mtx = action.reshape(6,6)\n",
    "\n",
    "#forbidden = forbidden_points[0,step_through,:]\n",
    "#forbidden_mtx = forbidden.reshape(6,6)\n",
    "\n",
    "#plot_board(state_mtx)\n",
    "#plot_board(action_mtx)\n",
    "plot_board(state_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(state_mtx.numpy())\n",
    "#print(glynn(state_mtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(glynn(state_mtx.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAGbCAYAAAASmD34AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVtUlEQVR4nO3de2zVhf3/8fdBRKjMKnL7Q90FGUZhCVAgiM7d0Gl0OO9kc9Nkiww2lIXqBKXr8IIUIXE6omMJU1FRI+BQvI7NuTEVXTY106mJ88IypxUUSrnY8/3jF/qT3/zJqfD24znfxyMh+fTTD55XCPbJp+e0LZXL5XIAQKJuRQ8AoPaJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSdS96QHNzc9ETAPiImpqaKrrOnQ0A6Qq/s9mhqXFK0RMq1txyXedxte4u33pZgUu6pjTxks7jatodUb3b7f541cLuXXFnA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQLqP9JM6N27cGJs2bYp99903evfuvac3AVBjKo5NR0dHLF68OG6++eb417/+1Xl+4MCBcdppp8XkyZOjVCqljASgulUcmzlz5sSaNWti+vTpceihh0avXr1i8+bN8eKLL8bChQujra0tGhsbM7cCUKUqjs1vfvObuOOOO+Kggw7a6fznP//5GDZsWJx11lliA8AHqvgFAtu3b4/+/ft/4Pv69OkT77333h4bBUBtqTg2o0ePjksuuSTefPPNnc63trbGrFmzYsyYMXt8HAC1oeJPo82ePTvOP//8OProo6O+vj7q6upi8+bNsX79+hg5cmRcc801mTsBqGIVx6ZPnz5x0003xSuvvBIvvPBCbNq0Kerq6mLw4MHx6U9/OnMjAFWuy19nc8ghh8QhhxySsQWAGuU7CACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIF2pXC6XixzQ3Nxc5MMDsBuampoqus6dDQDpxAaAdN2LHrBDU+OUoidUrLnlus7jat1dvvWyApd0TWniJZ3H1bQ7onq32/3xqoXdu+LOBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkK57Vy5+4okndnnNqFGjPvIYAGpTl2Izc+bMePXVV6NcLn/g+0ulUvz973/fI8MAqB1dis1tt90WZ511VkybNi2OP/74rE0A1JguPWfTp0+fuPLKK6OlpSU6OjqyNgFQY7r8AoGRI0fG1KlT4+23387YA0AN6tKn0XY4+eST9/AMAGqZlz4DkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASBdqVwul4sc0NzcXOTDA7AbmpqaKrrOnQ0A6cQGgHTdix6wQ1PjlKInVKy55brO42rdXb71sgKXdE1p4iWdx9W0O6J6t9v98aqF3bvizgaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAuopi8/bbb8ekSZNi1KhRcc4558SLL7640/tHjBiRMg6A2lBRbObMmRPlcjmuuuqq6N+/f3zrW9/aKTjlcjltIADVr3slF/3xj3+Me+65J+rr6+MrX/lKLFiwIM4777y46667or6+PkqlUvZOAKpYRXc227Zti969e3e+PW3atDj88MPjxz/+cUS4swHgw1UUmyOOOCIWLly4U1SuvPLKeP3112PGjBlp4wCoDRXF5sILL4ylS5fGeeed13mud+/eccMNN8SaNWuivb09bSAA1a+i52wOO+yweOihh2LdunU7nT/kkENixYoVcdddd6WMA6A2VPx1Nvvss0989rOf/a/z++23X5xzzjl7chMANcYXdQKQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIF2pXC6XixzQ3Nxc5MMDsBuampoqus6dDQDpxAaAdN2LHrBDU+OUoidUrLnlus7jat1dvvWyApd0TWniJZ3H1bQ7onq32/3xqoXdu+LOBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0C63YrNu+++G9u3b99TWwCoURXHZsuWLXHttdfGLbfcEu3t7fH9738/Ro8eHSNGjIjZs2fHtm3bMncCUMW6V3phS0tLPPbYY7F169ZYtWpVlEqlWLp0aWzdujXmzp0bCxcujKlTp2ZuBaBKVRyb++67L5YvXx6tra0xYcKEeOSRR6Jfv34REbFgwYL4zne+IzYAfKCKY7N58+bo27dv9O3bN/r37x/19fWd7+vfv3+8++67KQMBqH4VP2czaNCgWL58eURE/P73v48ePXpERMT27dtj/vz5MWzYsJSBAFS/iu9spk2bFpMmTYpjjz026urqOs+fdNJJsWXLlvjlL3+ZMhCA6ldxbMaOHRurV6/eKTQREVdccUUMGTLkv84DwA4VxyYiok+fPv91bvjw4XtsDAC1yXcQACCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0pXK5XC5yQHNzc5EPD8BuaGpqqug6dzYApBMbANJ16cdCZ2pqnFL0hIo1t1zXeWx3vmrdHVG929+/u3zrZQUu6ZrSxEs6j+3O9/7du+LOBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEg3W7FZvTo0XtqBwA1rHslF1188cUfeL6tra3zfVdeeeWeWwVATanozua1116Lu+++O9rb23c6XyqVUkYBUFsqurP59a9/HT//+c/joYceinnz5sWQIUMiIuLhhx92RwPALlV0Z9OtW7c4//zzY8aMGTF58uRYsmRJ9i4AakiXXiAwduzYuP322+O3v/1tTJ48OTo6OrJ2AVBDuvxqtAMPPDAWLVoUw4YNi379+mVsAqDGfKSXPpdKpfjBD34Qq1at2tN7AKhBvqgTgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpSuVyuVzkgObm5iIfHoDd0NTUVNF17mwASCc2AKTrXvSAHZoapxQ9oWLNLdd1Htudr1p3R1Tvdrs/XrWwe1fc2QCQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBut2LT1tYW27Zt21NbAKhRFcfmoosu6jx+5513YtKkSdHQ0BDDhw+PWbNmxdatW1MGAlD9Ko7Ngw8+2Hk8b968aGtri6VLl8bixYvjH//4R8ybNy9lIADVr+LYlMvlzuNHHnkk5s6dG8OGDYuGhoaYP39+3HPPPSkDAah+FcemVCr939/UrVsccMABnW8PGDAg2tvb9+wyAGpGxbHZsmVLzJgxI2655ZYYPHjwTncyixcvjsGDB6cMBKD6VRyblpaWqK+vj1WrVsUTTzwRy5Yti4iIq6++Oq699tqYPn162kgAqlv3Si884YQT4oQTToiI//P8TWtra0REnHjiifHtb387BgwYkLMQgKpXcWzer1QqxYEHHhgREUOGDNmjgwCoPb6DAADpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0pXK5XK5yAHNzc1FPjwAu6Gpqami69zZAJBObABI173oATuUb72s6AkVK028pPPY7nzVujuiere/f3dT45QCl3RNc8t1ncd253v/7l1xZwNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0C63YrN5s2bo62tbU9tAaBGVRyb//znPzFp0qR46aWXYsOGDTFp0qQYOXJkNDQ0xNSpU2Pjxo2ZOwGoYhXH5qc//Wn06NEj+vbtG3PmzIlt27bF0qVL45Zbbol33nknLr/88sydAFSx7pVeuHbt2li9enXU1dXFo48+GitWrIg+ffpERMT8+fPj+OOPTxsJQHXr0nM2HR0dERHRq1ev6NmzZ+f5nj17xt57771nlwFQMyqOzTHHHBMzZsyITZs2xcSJE2Pu3Lmxbdu22LRpU1x88cUxZsyYzJ0AVLGKP402c+bM+OEPfxjjxo2LQYMGxfPPPx933nlnlMvlOOigg+Lmm2/O3AlAFas4NvX19XHTTTfFM888E08//XRs2LAhevToEYMGDYpx48ZF9+4V/6cA+F+my4UYOnRoDB06NGMLADXKdxAAIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0C6UrlcLhc5oLm5uciHB2A3NDU1VXSdOxsA0okNAOm6Fz1gh6bGKUVPqFhzy3Wdx+VbLytwSdeUJl7SeWz3x+P926v173i17q6mvyu18PdkV9zZAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEhXcWy+8IUvxMqVKzO3AFCjKo5NR0dHzJ07N2bNmhVtbW2ZmwCoMRXHpkePHnHHHXfEyy+/HMcee2wsWbIk2tvbM7cBUCO6d+XiAQMGxI033hjLly+PhQsXxvz582P8+PHR0NAQAwYMiKOPPjprJwBVrEux2eHkk0+OCRMmxJ///Od44IEH4sYbb4zXXnstnnrqqT29D4AaUHFsyuXyTm+XSqUYO3ZsjB07do+PAqC2VPyczc9+9rPMHQDUsIpjc9JJJ2XuAKCG+aJOANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkK5X/35/3/DFrbm4u8uEB2A1NTU0VXVd4bACofT6NBkA6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAupqMzVtvvRWTJ0+OhoaGGDNmTFx++eWxffv2omdVrLW1NcaPHx+PPfZY0VMq8txzz8W5554bo0ePjnHjxsWFF14Yra2tRc/apTVr1sTpp58eI0aMiHHjxsXs2bOjvb296FkVe++99+Lss8+On/zkJ0VPqdi9994bhx9+eAwfPrzzV2NjY9Gzdmn9+vVx4YUXxpgxY2LUqFExefLkeOONN4qe9aHuvvvunf6chw8fHkOHDo2hQ4cWsqcmY3PBBRdEXV1d/OEPf4g777wz1qxZE4sXLy56VkWefPLJOPPMM+OVV14pekpF2tvb43vf+14MHz48Hn300Vi5cmWsX78+ZsyYUfS0D9Xa2hrnnXdeTJw4MdauXRvLli2Lxx9/PG644Yaip1Xs2muvjbVr1xY9o0uefvrpmDBhQvzlL3/p/NXS0lL0rF360Y9+FG1tbfHggw/G6tWrY6+99opLL7206Fkf6hvf+MZOf8733Xdf7L///nH55ZcXsqfmYvPPf/4zHn/88WhsbIxevXrFwQcfHJMnT44lS5YUPW2Xli1bFtOnT49p06YVPaVi69ati8MOOyymTJkSPXr0iAMOOCDOPPPMeOKJJ4qe9qH69OkTf/rTn+KUU06JUqkU69evjy1btkSfPn2KnlaRNWvWxAMPPBDHHnts0VO65Omnny7sX9Yf1TPPPBN//etfY86cObHffvtF7969Y/bs2TF9+vSip1WsXC5HY2NjfOlLX4oJEyYUsqHmYvPCCy/E/vvvHwMGDOg8N2jQoFi3bl288847BS7btaOOOioefPDBOOGEE4qeUrHPfe5zsWjRothrr706z91///1xxBFHFLiqMr17946IiGOOOSZOOumk6NevX5xyyikFr9q1t956K2bOnBlXX3119OrVq+g5Fevo6Ihnn302fve738WXv/zl+OIXvxiXXnppbNiwoehpH+pvf/tbHHrooXH77bfH+PHj46ijjoqrrroq+vXrV/S0iq1YsSJefPHFQj/lWnOx2bRp03/9D7jj7ba2tiImVaxfv37RvXv3omd8ZOVyORYsWBCrV6+OmTNnFj2nYg888EA88sgj0a1bt5g6dWrRcz5UR0dHNDY2xrnnnhuHHXZY0XO6pLW1NQ4//PA47rjj4t57743bbrstXn755U/8czYbNmyI559/Pl5++eVYtmxZLF++PP7973/HRRddVPS0inR0dMTChQtj0qRJnf/AKkL1fmT7/6irq4vNmzfvdG7H2/vuu28Rk/5X2LhxY1x88cXx7LPPxs033xxDhgwpelLFevbsGT179ozGxsY4/fTTY8OGDVFfX1/0rA90/fXXR48ePeLss88uekqX9e3bd6dPZ/fq1SsaGxvjjDPOiI0bNxb6gfDD9OjRIyIiZs6cGfvss0/07t07LrjggjjjjDNi06ZNn/iPK4899li88cYbcdpppxW6o+bubAYPHhzr16+PN998s/PcSy+9FAMHDoxPfepTBS6rXa+88kqceuqpsXHjxrjzzjurIjRPPfVUfP3rX4+tW7d2ntu6dWvsvffen+hPTa1YsSIef/zxaGhoiIaGhli5cmWsXLkyGhoaip62S88991zMmzcv3v8jtLZu3RrdunXr/ID+SXTooYdGR0dHbNu2rfNcR0dHRERUw48Du//++2P8+PFRV1dX6I6ai81nPvOZGDlyZFxxxRWxcePGePXVV+MXv/hF4VWvVRs2bIjvfve7MWLEiPjVr35VNU+wDxkyJNrb2+Pqq6+OrVu3xuuvvx5XXXVVnHbaaZ/oD3z33XdfPPXUU7F27dpYu3ZtnHjiiXHiiSdWxavS9t9//1iyZEksWrQotm/fHuvWrYuWlpb45je/+Yn+Mz/yyCPj4IMPjhkzZsSmTZuitbU1FixYEF/72tc+sXdj7/fkk0/GqFGjip5Re7GJiLjmmmti+/bt8dWvfjXOOOOMOProo2Py5MlFz6pJd911V6xbty5WrVoVI0eO3Ok1/Z9k++67byxatCheeOGFGDduXJx99tlx5JFHfuJfsl3NBg4cGNdff308/PDDMXr06Dj11FNj2LBhMWvWrKKnfai99947brrppthrr73iuOOOi+OOOy4GDhwYV1xxRdHTKvLaa69F//79i57hx0IDkK8m72wA+GQRGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0/wPnjEdpHewBHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "step_through = step\n",
    "#state = states[0,step_through,:]\n",
    "#state_mtx = state.reshape(6,6)\n",
    "\n",
    "#action = actions[0,step_through-1,:]\n",
    "#action_mtx = action.reshape(6,6)\n",
    "\n",
    "forbidden = forbidden_points[0,step_through,:]\n",
    "forbidden_mtx = forbidden.reshape(n,n)\n",
    "\n",
    "#plot_board(state_mtx)\n",
    "#plot_board(action_mtx)\n",
    "plot_board(forbidden_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "step_through = step\n",
    "#state = states[0,step_through,:]\n",
    "#state_mtx = state.reshape(6,6)\n",
    "\n",
    "action = actions[0,step_through-1,:]\n",
    "action_mtx = action.reshape(n,n)\n",
    "\n",
    "#forbidden = forbidden_points[0,step_through,:]\n",
    "#forbidden_mtx = forbidden.reshape(6,6)\n",
    "\n",
    "#plot_board(state_mtx)\n",
    "plot_board(action_mtx)\n",
    "#plot_board(forbidden_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[1, 14, 23, 63]\n"
     ]
    }
   ],
   "source": [
    "print(step)\n",
    "print(corner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add remaining points\n",
    "terminal = False\n",
    "while step < 4*n - 4: #4*n - 4:\n",
    "    step+=1\n",
    "    cur_state = states[i,step-1, :]\n",
    "    cur_forbidden = forbidden_points[i,step-1, :]\n",
    "\n",
    "    #tic = time.time()\n",
    "    #output = agent(cur_state)\n",
    "    #pred_time += time.time() - tic\n",
    "\n",
    "    output = agent(cur_state)\n",
    "\n",
    "    #tic = time.time()\n",
    "    new_state, action, new_forbidden_state = add_point(cur_state, output, cur_forbidden, corner_list, n)\n",
    "    #play_time += time.time() - tic\n",
    "\n",
    "    #tic = time.time()\n",
    "    #if terminal:\n",
    "    #    total_score[i] = cur_state.sum()\n",
    "    #    continue\n",
    "    actions[i,step-1, :] = action\n",
    "    #scoreUpdate_time += time.time() - tic\n",
    "\n",
    "    #tic = time.time()\n",
    "    states[i,step, :] = new_state\n",
    "    #recordsess_time += time.time() - tic\n",
    "\n",
    "    forbidden_points[i,step, :] = new_forbidden_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (nth session, always 4*n - 4 steps, always n*n board)\n",
    "states = torch.zeros((n_sessions, 4*n - 4, n*n))\n",
    "actions = torch.zeros((n_sessions, 4*n - 4, n*n))\n",
    "forbidden_points = torch.zeros((n_sessions, 4*n - 4, n*n))\n",
    "corners = torch.zeros((n_sessions, 4*n - 4, n*n))\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "while step < 3:\n",
    "    step += 1\n",
    "    cur_state = states[i,step-1, :]\n",
    "\n",
    "    new_state, action = add_free_points(cur_state, n, step)\n",
    "    \n",
    "    actions[i,step-1, :] = action\n",
    "    states[i,step, :] = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add corners\n",
    "corner_num = 0\n",
    "corner_list = [0]*(n-2) # there can be at most n-2 corners\n",
    "\n",
    "row_boundary, col_boundary = 0, 1\n",
    "\n",
    "row_zero_set = False\n",
    "terminal = False\n",
    "while not terminal:\n",
    "    step += 1\n",
    "    cur_state = states[i,step-1, :]\n",
    "\n",
    "    output = corner_agent(cur_state)\n",
    "\n",
    "    new_state, action, terminal, row_added, col_added = add_corner(cur_state, output, n, row_boundary, col_boundary)\n",
    "    \n",
    "    # Ensures that a corner is always set in first row. If the lower block is entered, essentially sets (1,2), 1-indexed, as the first corner\n",
    "    # then artifically using the above point as the next step. The lower black can only be entered once.\n",
    "    if row_added == 0:\n",
    "        row_zero_set = True\n",
    "    if not row_zero_set:\n",
    "        cur_state = torch.clone(states[i,step-1, :])\n",
    "        cur_state[1] = 1\n",
    "\n",
    "        actions[i,step-1, 1] = 1\n",
    "        states[i,step, :] = cur_state\n",
    "        corners[i,step, 1] = 1\n",
    "    \n",
    "        corner_list[corner_num] = 1 # the first corner is at index 1\n",
    "        corner_num += 1\n",
    "    \n",
    "        step += 1\n",
    "        row_zero_set = True\n",
    "\n",
    "        new_state[1] = 1\n",
    "    ''' need to account for attempted corners in second column, other than index 1 '''\n",
    "    corner_index = row_added*n + col_added\n",
    "    corner_list[corner_num] = corner_index\n",
    "    corners[i,step, corner_index] = 1\n",
    "\n",
    "    corner_num += 1\n",
    "\n",
    "    row_boundary = row_added + 1\n",
    "    col_boundary = col_added + 1\n",
    "\n",
    "    actions[i,step-1, :] = action\n",
    "    states[i,step, :] = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune corner list\n",
    "corner_list = corner_list[:corner_num]\n",
    "corner_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add induced corners\n",
    "for corner_index in corner_list:\n",
    "    step += 1\n",
    "    cur_state = torch.clone(states[i,step-1, :])\n",
    "    #cur_forbidden = torch.clone(forbidden_points[i,step-1, :])\n",
    "\n",
    "    corner_row = corner_index//n\n",
    "    corner_col = corner_index%n\n",
    "    # induced corner = (i+1, j-1) -> (i+1)n + (j-1), where i=row and j=col\n",
    "    induced_corner_index = (corner_row+1)*n + (corner_col-1)\n",
    "    cur_state[induced_corner_index] = 1\n",
    "\n",
    "    actions[i,step-1, induced_corner_index] = 1\n",
    "    states[i,step, :] = cur_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zig-zag and upper forbidden points\n",
    "corner_list.append(n**2-1) # n^2-1 is not a corner, but we append it to work with while-loop below\n",
    "corner_list.append(float('inf'))\n",
    "cur_path_element = 1 # first element on the zig-zag path, besides upper-left corner\n",
    "target_corner_num = 0\n",
    "target_corner = corner_list[target_corner_num]\n",
    "\n",
    "# first row\n",
    "while cur_path_element != target_corner:\n",
    "    # action\n",
    "    step += 1\n",
    "    cur_state = torch.clone(states[i,step-1, :])\n",
    "    cur_state[cur_path_element] = 1\n",
    "\n",
    "    actions[i,step-1, cur_path_element] = 1\n",
    "    states[i,step, :] = cur_state\n",
    "\n",
    "    cur_path_element += 1 # step element by one row, fixing column\n",
    "\n",
    "# update forbidden states\n",
    "cur_forbidden_state = torch.clone(forbidden_points[i,step-1, :])\n",
    "for forbidden_index in range(cur_path_element+1, n):\n",
    "    cur_forbidden_state[forbidden_index] = 1 \n",
    "forbidden_points[i, step, :] = cur_forbidden_state\n",
    "\n",
    "target_corner_num += 1\n",
    "target_corner = corner_list[target_corner_num]  \n",
    "\n",
    "while cur_path_element < n**2-n-1:\n",
    "    target_row = target_corner//n\n",
    "    #target_col = target_corner%n\n",
    "\n",
    "    cur_row = cur_path_element//n\n",
    "    cur_col = cur_path_element%n\n",
    "\n",
    "    while cur_path_element != target_corner: # incorrect row OR incorrect column\n",
    "        if cur_row != target_row: # must move row\n",
    "            # update forbidden states\n",
    "            cur_forbidden_state = torch.clone(forbidden_points[i,step-1, :])\n",
    "            for forbidden_index in range(cur_path_element+1, cur_row*n + n):\n",
    "                cur_forbidden_state[forbidden_index] = 1 \n",
    "            forbidden_points[i, step, :] = cur_forbidden_state\n",
    "            # action\n",
    "            step += 1\n",
    "            cur_state = torch.clone(states[i,step-1, :])\n",
    "            cur_path_element += n # step element by one row, fixing column\n",
    "            cur_state[cur_path_element] = 1\n",
    "\n",
    "            actions[i,step-1, cur_path_element] = 1\n",
    "            states[i,step, :] = cur_state\n",
    "\n",
    "            cur_row += 1\n",
    "        else: # cur_col != target_col, i.e, correct row but must move column\n",
    "            # action\n",
    "            cur_path_element += 1\n",
    "            if cur_path_element != target_corner:\n",
    "                step += 1\n",
    "                cur_state = torch.clone(states[i,step-1, :])\n",
    "                #cur_path_element += 1 # step element by one column, fixing row\n",
    "                cur_state[cur_path_element] = 1\n",
    "\n",
    "                actions[i,step-1, cur_path_element] = 1\n",
    "                states[i,step, :] = cur_state\n",
    "\n",
    "                cur_col += 1\n",
    "    target_corner_num += 1\n",
    "    target_corner = corner_list[target_corner_num]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAGbCAYAAAASmD34AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAASAklEQVR4nO3dbWzVd93H8e9BxHGj3TruHijeTIQw+wDoWCZOo8aphGW6sRui6JZowJIwMXQ6QJqGObYVRjKZZBMTjGMbusCmbMzdOMUbMsD5YFlcZCbKXH2ydbBBKaXruR5coRfNyMVh9Nu/Pef1SkhO/z2kn1+28s6/PYVSuVwuBwAkGlb0AACqn9gAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIN3woge0trYWPQGAd6ilpaWi57mzASBd4Xc2J5QfuKXoCYOiNH9l3+NaOXNE/3O3NC8ucMngam27u+9xrZy7Fs8cUZvnPvnMp+POBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0w9/Jbzp8+HAcOXIkRo8eHWPGjBnoTQBUmYpj09vbG5s3b4777rsv/vOf//RdnzhxYsybNy+ampqiVCqljARgaKs4Nrfddlvs3r07li1bFh/96Edj5MiRcfTo0XjppZdi48aN0dnZGc3NzZlbARiiKo7Nr3/96/jlL38Z73//+/td/9jHPhYNDQ1x3XXXiQ0Ap1TxCwR6enpi/Pjxp3xffX19vPXWWwM2CoDqUnFsZs2aFStXroxXX3213/WOjo5YtWpVXHzxxQM+DoDqUPGX0VavXh033nhjXHrppVFXVxejRo2Ko0ePxsGDB2PmzJlx1113Ze4EYAirODb19fXx85//PA4cOBD79++PI0eOxKhRo2Ly5MnxwQ9+MHMjAEPcGf+czaRJk2LSpEkZWwCoUv4GAQDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASFcql8vlIge0trYW+eEBOAstLS0VPc+dDQDpxAaAdMOLHnBC+YFbip4wKErzV/Y9rpUzR/Q/d0vz4gKXDK7Wtrv7HtfKuWvxzBG1ee6Tz3w67mwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6YafyZP37t172udcdNFF73gMANXpjGKzYsWKePnll6NcLp/y/aVSKf72t78NyDAAqscZxebBBx+M6667LpYuXRpf+tKXsjYBUGXO6Hs29fX1sWbNmmhra4ve3t6sTQBUmTN+gcDMmTNjyZIl8frrr2fsAaAKndGX0U748pe/PMAzAKhmXvoMQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdKVyuVwuckBra2uRHx6As9DS0lLR89zZAJBObABIN7zoASe0NC8uesKgaG27u+9x+YFbClwyuErzV/Y9du7qdvKZa+XzOqL/53atnPvkM5+OOxsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOkqis3rr78eixYtiosuuiiuv/76eOmll/q9f8aMGSnjAKgOFcXmtttui3K5HLfffnuMHz8+vvrVr/YLTrlcThsIwNA3vJIn/elPf4pHH3006urq4rOf/WysX78+Fi5cGNu2bYu6uroolUrZOwEYwiq6szl+/HiMGTOm7+2lS5fGtGnT4rvf/W5EuLMB4P9XUWwuvPDC2LhxY7+orFmzJl555ZVYvnx52jgAqkNFsbnpppti69atsXDhwr5rY8aMiXvvvTd2794dXV1daQMBGPoq+p7N1KlT46mnnor29vZ+1ydNmhSPPPJIbNu2LWUcANWh4p+zec973hMf/vCH33b9fe97X1x//fUDuQmAKuOHOgFIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIF2pXC6XixzQ2tpa5IcH4Cy0tLRU9Dx3NgCkExsA0g0vesAJLc2Li54wKFrb7u57XCtnjuh/7vIDtxS4ZHCV5q/se1wr567FM0f0P3etfG6f/Hl9Ou5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEh3VrF58803o6enZ6C2AFClKo7NsWPHYsOGDXH//fdHV1dXfOtb34pZs2bFjBkzYvXq1XH8+PHMnQAMYcMrfWJbW1s8++yz0d3dHTt37oxSqRRbt26N7u7uuOOOO2Ljxo2xZMmSzK0ADFEVx+bxxx+Phx9+ODo6OuKKK66IXbt2xbhx4yIiYv369fH1r39dbAA4pYpjc/To0Rg7dmyMHTs2xo8fH3V1dX3vGz9+fLz55pspAwEY+ir+ns0FF1wQDz/8cERE/P73v48RI0ZERERPT0/ceeed0dDQkDIQgKGv4jubpUuXxqJFi+Kyyy6LUaNG9V2//PLL49ixY/GTn/wkZSAAQ1/FsbnkkkvimWee6ReaiIhbb701pkyZ8rbrAHBCxbGJiKivr3/btenTpw/YGACqk79BAIB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOlK5XK5XOSA1tbWIj88AGehpaWloue5swEgndgAkG540QNOaGleXPSEQdHadnff41o5c4RzR0SUH7ilwCWDpzR/Zd/jWjlzRG2e++Qzn447GwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6c4qNrNmzRqoHQBUseGVPOnmm28+5fXOzs6+961Zs2bgVgFQVSq6s/n3v/8dv/rVr6Krq6vf9VKplDIKgOpS0Z3Nz372s/jRj34UTz31VKxduzamTJkSERFPP/20OxoATquiO5thw4bFjTfeGMuXL4+mpqbYsmVL9i4AqsgZvUDgkksuiV/84hfx29/+NpqamqK3tzdrFwBV5IxfjXb++efHpk2boqGhIcaNG5exCYAq845e+lwqleLb3/527Ny5c6D3AFCF/FAnAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0pXK5XK5yAGtra1FfngAzkJLS0tFz3NnA0A6sQEg3fCiB5xQfuCWoicMitL8lX2PW5oXF7hkcLW23d332Lmr28lnrpXP64j+n9u1cu6Tz3w67mwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkE5sAEgnNgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASHdWsens7Izjx48P1BYAqlTFsfne977X9/iNN96IRYsWRWNjY0yfPj1WrVoV3d3dKQMBGPoqjs2TTz7Z93jt2rXR2dkZW7dujc2bN8ff//73WLt2bcpAAIa+imNTLpf7Hu/atSvuuOOOaGhoiMbGxrjzzjvj0UcfTRkIwNBXcWxKpdL//aZhw+K8887re3vChAnR1dU1sMsAqBoVx+bYsWOxfPnyuP/++2Py5Mn97mQ2b94ckydPThkIwNBXcWza2tqirq4udu7cGXv37o3t27dHRMS6detiw4YNsWzZsrSRAAxtwyt94pw5c2LOnDkR8b/fv+no6IiIiLlz58bXvva1mDBhQs5CAIa8imNzslKpFOeff35EREyZMmVABwFQffwNAgCkExsA0okNAOnEBoB0YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6cQGgHRiA0A6sQEgndgAkK5ULpfLRQ5obW0t8sMDcBZaWloqel7hsQGg+vkyGgDpxAaAdGIDQDqxASCd2ACQTmwASCc2AKQTGwDSiQ0A6WouNq+99lo0NTVFY2NjXHzxxfHDH/4wenp6ip41aDo6OuLzn/98PPvss0VPSffiiy/GDTfcELNmzYrZs2fHTTfdFB0dHUXPSrd79+64+uqrY8aMGTF79uxYvXp1dHV1FT1rULz11luxYMGC+P73v1/0lEHx2GOPxbRp02L69Ol9v5qbm4uedUo1F5vvfOc7MWrUqPjDH/4QDz30UOzevTs2b95c9KxB8Ze//CWuvfbaOHDgQNFT0nV1dcU3v/nNmD59evzxj3+MHTt2xMGDB2P58uVFT0vV0dERCxcujPnz58e+ffti+/btsWfPnrj33nuLnjYoNmzYEPv27St6xqB5/vnn44orroi//vWvfb/a2tqKnnVKNRWbf/3rX7Fnz55obm6OkSNHxgc+8IFoamqKLVu2FD0t3fbt22PZsmWxdOnSoqcMivb29pg6dWosXrw4RowYEeedd15ce+21sXfv3qKnpaqvr48///nPceWVV0apVIqDBw/GsWPHor6+vuhp6Xbv3h1PPPFEXHbZZUVPGTTPP/98fPzjHy96RkVqKjb79++Pc889NyZMmNB37YILLoj29vZ44403ClyW75Of/GQ8+eSTMWfOnKKnDIqPfOQjsWnTpnjXu97Vd+03v/lNXHjhhQWuGhxjxoyJiIhPf/rTcfnll8e4cePiyiuvLHhVrtdeey1WrFgR69ati5EjRxY9Z1D09vbGCy+8EL/73e/iM5/5THzqU5+KH/zgB3Ho0KGip51STcXmyJEjb/sf8cTbnZ2dRUwaNOPGjYvhw4cXPaMQ5XI51q9fH88880ysWLGi6DmD5oknnohdu3bFsGHDYsmSJUXPSdPb2xvNzc1xww03xNSpU4ueM2g6Ojpi2rRp8YUvfCEee+yxePDBB+Of//znf+33bGrqT59Ro0bF0aNH+1078fbo0aOLmESyw4cPx8033xwvvPBC3HfffTFlypSiJw2ac845J84555xobm6Oq6++Og4dOhR1dXVFzxpw99xzT4wYMSIWLFhQ9JRBNXbs2H7fAhg5cmQ0NzfHNddcE4cPH+67w/1vUVN3NpMnT46DBw/Gq6++2nftH//4R0ycODHe+973FriMDAcOHIirrroqDh8+HA899FBNhOa5556LL37xi9Hd3d13rbu7O9797ndX7ZeXHnnkkdizZ080NjZGY2Nj7NixI3bs2BGNjY1FT0v14osvxtq1a+Pkf5Ksu7s7hg0bFiNGjChw2anVVGw+9KEPxcyZM+PWW2+Nw4cPx8svvxw//vGPY968eUVPY4AdOnQovvGNb8SMGTPipz/9aU18gzwiYsqUKdHV1RXr1q2L7u7ueOWVV+L222+PefPm/Vf+ATQQHn/88Xjuuedi3759sW/fvpg7d27MnTu36l+Vdu6558aWLVti06ZN0dPTE+3t7dHW1hZf+cpX/iv/W9dUbCIi7rrrrujp6YnPfe5zcc0118Sll14aTU1NRc9igG3bti3a29tj586dMXPmzH4/h1DNRo8eHZs2bYr9+/fH7NmzY8GCBfGJT3yi6l/yXYsmTpwY99xzTzz99NMxa9asuOqqq6KhoSFWrVpV9LRT8s9CA5Cu5u5sABh8YgNAOrEBIJ3YAJBObABIJzYApBMbANKJDQDpxAaAdGIDQDqxASCd2ACQ7n8AN4HIEEvipx8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_through = step\n",
    "state = states[0,step_through,:]\n",
    "state_mtx = state.reshape(6,6)\n",
    "\n",
    "action = actions[0,step_through-1,:]\n",
    "action_mtx = action.reshape(6,6)\n",
    "\n",
    "forbidden = forbidden_points[0,step_through,:]\n",
    "forbidden_mtx = forbidden.reshape(6,6)\n",
    "\n",
    "plot_board(state_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(action_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(forbidden_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(matrix):\n",
    "\n",
    "    n = len(matrix)\n",
    "    data = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if matrix[i][j] == 1:\n",
    "                data[i][j] = 1\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "    sns.heatmap(data, cmap='Oranges', square=True, cbar=False, linewidth=1,\n",
    "                linecolor='gray', annot=False, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sessions = 1 # number of sessions per iteration\n",
    "Learning_rate = 0.001 # learning rate, increase this to converge faster\n",
    "\n",
    "n = 8\n",
    "\n",
    "input_space = n*n\n",
    "INF = 1000000\n",
    "\n",
    "first_layer_neurons = 128\n",
    "second_layer_neurons = 64\n",
    "third_layer_neurons = 4\n",
    "last_layer_neurons = n*n\n",
    "\n",
    "# Defining the neural network architecture\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_space, first_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_layer_neurons, second_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_layer_neurons, third_layer_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(third_layer_neurons, last_layer_neurons)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create neural network for corners\n",
    "corner_agent = MyNet()\n",
    "\n",
    "# Create neural network for all other points\n",
    "agent = MyNet()\n",
    "\n",
    "# Definte the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "corner_optimizer = optim.SGD(corner_agent.parameters(), lr=Learning_rate)\n",
    "optimizer = optim.SGD(agent.parameters(), lr=Learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
