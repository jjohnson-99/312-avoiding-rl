{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using Plots\n",
    "using Base.Threads\n",
    "using Flux\n",
    "using Base.Iterators: product\n",
    "using Flux: Optimise\n",
    "using Flux: ADAM, params, update!\n",
    "using Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"permanents.jl\")\n",
    "\n",
    "# Variables are for reward_function.jl\n",
    "Lambda = 0.35 # Weight for regularizing the reward function to generate more ones (too high a labda will result in higher odds of generating isosceles triangles)\n",
    "\n",
    "# Variables are for bitwise_model.jl\n",
    "n_actions = 2  # Number of actions that the agent can take. In this case, it is either 0 for excluding a point and 1 for including it\n",
    "n_sessions = 2000  # Number of new sessions per iteration\n",
    "learning_rate = 0.001  # Learning rate, increase this to converge faster\n",
    "percentile = 90  # Top 100-x percentile the agent will learn from\n",
    "super_percentile = 90  # Top 100-x percentile of that survives to the next generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables are for bitwise_model.jl\n",
    "n_actions = 2  # Number of actions that the agent can take. In this case, it is either 0 for excluding a point and 1 for including it\n",
    "n_sessions = 2000  # Number of new sessions per iteration\n",
    "learning_rate = 0.001  # Learning rate, increase this to converge faster\n",
    "percentile = 90  # Top 100-x percentile the agent will learn from\n",
    "super_percentile = 90  # Top 100-x percentile of that survives to the next generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "board_to_string (generic function with 2 methods)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function board_to_string(board::Vector{Int64}, n)\n",
    "    # board is currently a Vector\n",
    "    board = reshape(convert(Vector{Int}, board), (n,n))\n",
    "    \n",
    "    output = \"[\"\n",
    "    for i in 1:n-1\n",
    "        output = output * string(board[:,i]) * '\\n' * ' '\n",
    "    end\n",
    "    output = output * string(board[:,n]) * \"]\"\n",
    "\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_point_allowed (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function new_point_allowed(one_indices, new_point_index, n)\n",
    "    row = ceil(Int, new_point_index / n)\n",
    "    col = new_point_index % n\n",
    "    if col == 0; col = n end # julia is 1-indexed, so x*n mod(n) must be n rather than 0\n",
    "\n",
    "    point_allowed = true\n",
    "\n",
    "    for i in 1:length(one_indices) \n",
    "        for j in i+1:length(one_indices)\n",
    "            point_one_row = ceil(Int, one_indices[i] / n)\n",
    "            point_two_row = ceil(Int, one_indices[j] / n)\n",
    "            #if point_one_row == 0; point_one_row end\n",
    "            #if point_two_row == 0; point_two_row end\n",
    "\n",
    "            point_one_col = one_indices[i] % n\n",
    "            point_two_col = one_indices[j] % n\n",
    "            if point_one_col == 0; point_one_col = n end\n",
    "            if point_two_col == 0; point_two_col = n end\n",
    "\n",
    "            if (  (row == point_one_row)\n",
    "                | (row == point_two_row)\n",
    "                | (point_one_row == point_two_row)\n",
    "                | (col == point_one_col)\n",
    "                | (col == point_two_col)\n",
    "                | (point_one_col == point_two_col))\n",
    "                continue\n",
    "            end\n",
    "            \n",
    "            # ensure point_one_col < point_two_col\n",
    "            if (point_two_col < point_one_col)\n",
    "                point_one_row, point_two_row = point_two_row, point_one_row\n",
    "                point_one_col, point_two_col = point_two_col, point_one_col\n",
    "            end\n",
    "\n",
    "            # new point as 1 in a valid 312-pattern\n",
    "            if ((point_two_row < point_one_row < row) & (point_one_col < col < point_two_col))\n",
    "                point_allowed = false\n",
    "                break\n",
    "            end\n",
    "\n",
    "            # new point as 2 in a valid 312-pattern\n",
    "            if ((point_two_row < row < point_one_row) & (col < point_one_col))\n",
    "                point_allowed = false\n",
    "                break\n",
    "            end\n",
    "\n",
    "            # new point as 3 in a valid 312-pattern\n",
    "            if ((row < point_one_row < point_two_row) & (point_two_col < col))\n",
    "                point_allowed = false\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if point_allowed == false\n",
    "            break\n",
    "        end\n",
    "        \n",
    "    end\n",
    "\n",
    "    return point_allowed\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_point (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_point(input_state, action_vec, n)\n",
    "    point_added = false\n",
    "    action_taken = zeros(n^2)\n",
    "    cur_state = copy(input_state)\n",
    "    \n",
    "    while !point_added\n",
    "        action_index = StatsBase.sample(collect(1:length(action_vec)), Weights(action_vec), 1)[1]\n",
    "        one_indices = findall(!iszero, input_state)\n",
    "        action_allowed = new_point_allowed(one_indices, action_index, n)\n",
    "        \n",
    "        if (cur_state[action_index] == 0) & (action_allowed)\n",
    "            cur_state[action_index] = 1\n",
    "            action_taken = action_index\n",
    "            point_added = true\n",
    "        else\n",
    "            action_vec[action_index] = 0\n",
    "            action_vec = action_vec ./ sum(action_vec)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return cur_state, action_taken\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4Ã—4 adjoint(::Matrix{Float64}) with eltype Float64:\n",
       " 1.0  1.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0\n",
       " 0.0  1.0  1.0  1.0\n",
       " 1.0  1.0  0.0  1.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sessions = 3\n",
    "n = 4\n",
    "\n",
    "i = 1\n",
    "\n",
    "states = zeros(n_sessions, 4*n - 4 + 1, n^2)\n",
    "actions = zeros(n_sessions, 4*n - 4 + 1)\n",
    "scores = zeros(n_sessions)\n",
    "\n",
    "for i in 1:n_sessions\n",
    "    step_ = 0\n",
    "    while step_ < 4*n - 4\n",
    "        step_ += 1\n",
    "        cur_state = states[i, step_, :]\n",
    "\n",
    "        output = net(cur_state)\n",
    "        next_state, action = add_point(cur_state, output, n)\n",
    "\n",
    "        actions[i, step_, :] = action\n",
    "        states[i, step_ + 1, :] = next_state\n",
    "    end\n",
    "    final_state = states[i, step_ + 1, :]\n",
    "    final_state_matrix = reshape(final_state, (n,n))\n",
    "    scores[i] = glynn(final_state_matrix)\n",
    "end\n",
    "\n",
    "M = reshape(states[1,4*n - 4 + 1,:], (n,n))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_session (generic function with 1 method)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_session(agent, n_sessions, n)\n",
    "    states = zeros(Int, n_sessions, 4*n - 4 + 1, n^2)\n",
    "    actions = zeros(Int, n_sessions, 4*n - 4 + 1)\n",
    "    scores = zeros(Int, n_sessions)\n",
    "    cur_state = zeros(Int, n^2)\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for i in 1:n_sessions # [1, n_sessions] inclusive\n",
    "        step = 0\n",
    "        while step < 4*n - 4 # there are 4*n - 4 steps total, starts at 0 and ends at 4*n - 4 -+? 1\n",
    "            \n",
    "            step += 1\n",
    "            # current board\n",
    "            cur_state .= states[i, step, :]\n",
    "\n",
    "            output = agent(cur_state)\n",
    "\n",
    "            next_state, action = add_point(cur_state, output, n)\n",
    "\n",
    "            actions[i, step] = action\n",
    "            states[i, step + 1, :] = next_state\n",
    "\n",
    "        final_state = states[i, step + 1, :]\n",
    "        final_state_matrix = reshape(final_state, (n,n))\n",
    "        scores[i] = glynn(final_state_matrix)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return states, actions, scores\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_super_sessions (generic function with 1 method)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_super_sessions(states_batch, actions_batch, rewards_batch, super_percentile)\n",
    "    counter = n_sessions * (100 - super_percentile) / 100\n",
    "    reward_threshold = quantile(rewards_batch, super_percentile / 100)\n",
    "\n",
    "    super_states = zeros(Int, 0, size(states_batch, 2), size(states_batch, 3))\n",
    "    super_actions = Matrix{Int}(undef, 0, size(actions_batch, 2))\n",
    "    super_rewards = Vector{Int}(undef, 0)\n",
    "    #println(\"in super_states after resetting to zeros: \" * string(size(super_states)))\n",
    "    #println(\"in super_actions after resetting to zeros: \" *string(size(super_actions)))\n",
    "    for i in 1:size(states_batch, 1)\n",
    "        #println(\"in super_states in for loop: \" * string(size(super_states)))\n",
    "        #println(\"in super_actions in for loop: \" *string(size(super_actions)))\n",
    "        if rewards_batch[i] >= reward_threshold - 0.000001 && counter > 0\n",
    "            temp_state = reshape(states_batch[i, :, :], (1,size(states_batch[i, :, :])...))\n",
    "            super_states = cat(super_states, temp_state; dims=1)\n",
    "\n",
    "            temp_actions = reshape(actions_batch[i, :], (1,size(actions_batch[i, :])...))\n",
    "            super_actions = cat(super_actions, temp_actions; dims=1)\n",
    "\n",
    "            push!(super_rewards, rewards_batch[i])\n",
    "\n",
    "            counter -= 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #println(size(super_states), size(super_rewards))\n",
    "    return super_states, super_actions, super_rewards\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_elites (generic function with 1 method)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    counter = n_sessions * (100 - percentile) / 100\n",
    "    reward_threshold = quantile(rewards_batch, percentile / 100)\n",
    "\n",
    "    elite_states = Matrix{Int}(undef, 0, size(states_batch, 3))\n",
    "    elite_actions = Vector{Int}(undef, 0)\n",
    "\n",
    "    #println(\"in elites: states_batch: \" * string(size(states_batch)))\n",
    "    #println(size(rewards_batch))\n",
    "    \n",
    "    for i in 1:size(states_batch, 1)\n",
    "        if rewards_batch[i] >= reward_threshold - 0.000001 && counter > 0\n",
    "            for item in eachrow(states_batch[i, :, :])\n",
    "                temp_state = reshape(item, 1, size(states_batch, 3)) # size of board\n",
    "                elite_states = vcat(elite_states, temp_state)\n",
    "            end\n",
    "\n",
    "            for item in actions_batch[i, :]\n",
    "                push!(elite_actions, item)\n",
    "            end\n",
    "\n",
    "            counter -= 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return elite_states, elite_actions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(board_size, filename)\n",
    "    n_sessions = 100\n",
    "    Learning_rate = 0.0001\n",
    "\n",
    "    n = board_size\n",
    "    input_space = n*n\n",
    "\n",
    "    first_layer_neurons = 128\n",
    "    second_layer_neurons = 64\n",
    "    third_layers_neurons = 4\n",
    "\n",
    "    # Define the neural network architecture (similar to PyTorch)\n",
    "    model = Chain(\n",
    "        Dense(n^2, first_layer_neurons, relu),\n",
    "        Dense(first_layer_neurons, second_layer_neurons, relu),\n",
    "        Dense(second_layer_neurons, third_layers_neurons, relu),\n",
    "        Dense(third_layers_neurons, n^2, Ïƒ)\n",
    "    )\n",
    "\n",
    "    # Create an instance of the neural network\n",
    "    net = model\n",
    "\n",
    "    # Defining the loss function and optimizer (similar to PyTorch)\n",
    "    criterion(y_pred, y_true) = Flux.binarycrossentropy(y_pred, y_true)\n",
    "    optimizer = Optimise.ADAM(learning_rate)\n",
    "\n",
    "    # Global lists\n",
    "    global super_states = Array{Int}(undef, 0, 4*n - 4 + 1, n^2)\n",
    "    global super_actions = Array{Int}(undef, 0, 4*n - 4 + 1)\n",
    "    global super_rewards = Int[]\n",
    "\n",
    "    cur_best_reward = 0\n",
    "    cur_best_board = []\n",
    "    cur_best_game = []\n",
    "    local best_states_set\n",
    "    \n",
    "    for i in 1:10\n",
    "        println(\"\\n GENERATION $i\")\n",
    "        states_batch, actions_batch, rewards_batch = generate_session(net, n_sessions, n)\n",
    "        #println(\"new batch size: \" * string(size(states_batch)))\n",
    "\n",
    "        if i > 1\n",
    "            states_batch = cat(states_batch, super_states; dims=1)\n",
    "            actions_batch = cat(actions_batch, super_actions; dims=1)\n",
    "            rewards_batch = cat(rewards_batch, super_rewards; dims=1)\n",
    "            #println(\"super size: \" * string(size(super_states)))\n",
    "        end\n",
    "        #println(\"batch size after cat: \" * string(size(states_batch)))\n",
    "\n",
    "        elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "        # sessions[1][i,:,:] are the states corresponding to the ith session\n",
    "        # likewise for actions and rewards\n",
    "        # the outer dimension is now the number of sessions\n",
    "        # the next dimension indicates (1 = states, 2 = actions, 3 = rewards)\n",
    "        # reverse sort the sessions (in the outer dimension) based on the rewards\n",
    "        # sessions = select_super_sessions(states_batch, actions_batch, rewards_batch, super_percentile)\n",
    "        ###\n",
    "        super_states, super_actions, super_rewards = select_super_sessions(states_batch, actions_batch, rewards_batch, super_percentile)\n",
    "        sessions = [super_states, super_actions, super_rewards]\n",
    "\n",
    "        ### error: this is not updating super_states, below we concat with old super_states.. error below\n",
    "        #println(\"new super size: \" * string(size(super_states))) # this is not new, this is old\n",
    "        #println(size(sessions[1]))\n",
    "        super_sessions = [[sessions[1][i,:,:], sessions[2][i,:], sessions[3][i]] for i in 1:length(sessions[3])]\n",
    "        #println(size(super_sessions))\n",
    "        sort!(super_sessions, by = x -> x[3], rev=true)\n",
    "\n",
    "        #### delete\n",
    "        #if i == 2\n",
    "        #    println(board_to_string(super_sessions[1][1][4*n - 4 + 1,:],n)) # 1st session, states of first session, last state\n",
    "        #    println(super_sessions[1][3])\n",
    "        #end\n",
    "\n",
    "        # optimize\n",
    "        # Backward pass (gradients calculation) and optimization (similar to PyTorch)\n",
    "        outputs = zeros(Float32, size(elite_states, 1), 1)\n",
    "        for i in 1:size(elite_states,1)\n",
    "            outputs[i] = model(elite_states[i, :, :])[1]\n",
    "        end\n",
    "\n",
    "        loss = criterion(outputs, elite_actions)\n",
    "        grads = gradient(() -> loss, params(model))\n",
    "        Optimise.update!(optimizer, params(model), grads)\n",
    "\n",
    "        # retrieve the sorted states, actions, rewards\n",
    "        # i corresponds to the ith session, 1 corresponds to the states of the ith session\n",
    "        # this is initally size (4n-4+1, n^2) but needs to be (1, 4n-4+1, n^2)\n",
    "\n",
    "        #####\n",
    "        # TODO\n",
    "        # currently just resetting super_states, need to stack them\n",
    "        # possible error here, fix here or above.\n",
    "        super_states = Array{Int}(undef, 0, 4*n - 4 + 1, n^2)\n",
    "        super_actions = Array{Int}(undef, 0, 4*n - 4 + 1)\n",
    "        for i in 1:length(super_sessions)\n",
    "            # just use super_states_reshaped?\n",
    "            super_states_reshaped = reshape(super_sessions[i][1], (1, size(super_sessions[i][1])...))\n",
    "            super_states = cat(super_states, super_states_reshaped; dims=1)\n",
    "\n",
    "            super_actions_reshaped = reshape(super_sessions[i][2], (1, size(super_sessions[i][2])...))\n",
    "            super_actions = cat(super_actions, super_actions_reshaped; dims=1)\n",
    "        end\n",
    "        super_rewards = [super_sessions[i][3] for i in 1:length(super_sessions)]\n",
    "\n",
    "        mean_best_reward = mean(super_rewards)\n",
    "\n",
    "        println(\"\\n$i. Best individuals: \", super_rewards)\n",
    "        # Uncomment the line below to print out the mean best reward\n",
    "        println(\"Mean best reward: $mean_best_reward\")\n",
    "\n",
    "        # Make a new folder if 'Data' folder does not exist\n",
    "        if !isdir(\"Data\")\n",
    "            mkdir(\"Data\")\n",
    "        end\n",
    "\n",
    "        max_index = argmax(super_rewards)\n",
    "        #max_index = 1\n",
    "\n",
    "        if super_rewards[max_index] > cur_best_reward\n",
    "            cur_best_reward = super_rewards[max_index]\n",
    "            cur_best_board = super_states[max_index, 4*n-4+1,:] # best board as vector\n",
    "            cur_best_game = super_states[max_index,:,:]\n",
    "\n",
    "            best_states_set = Set()\n",
    "            push!(best_states_set, string(cur_best_board))\n",
    "            \n",
    "            # add to file\n",
    "            open(joinpath(\"Data\", filename * \"_best_board_timeline.txt\"), \"a\") do f\n",
    "                write(f, board_to_string(cur_best_board, n), '\\n')\n",
    "            end\n",
    "            open(joinpath(\"Data\", filename * \"_best_reward_timeline.txt\"), \"a\") do f\n",
    "                write(f, string(cur_best_reward), '\\n')\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if super_rewards[max_index] == cur_best_reward\n",
    "            cur_best_board = super_states[max_index, 4*n-4+1,:] # best board as vector\n",
    "            if !in(string(cur_best_board), best_states_set)\n",
    "                push!(best_states_set, string(cur_best_board))\n",
    "\n",
    "                # add to file\n",
    "                open(joinpath(\"Data\", filename * \"_best_board_timeline.txt\"), \"a\") do f\n",
    "                    write(f, board_to_string(cur_best_board, n), '\\n')\n",
    "                end\n",
    "                open(joinpath(\"Data\", filename * \"_best_reward_timeline.txt\"), \"a\") do f\n",
    "                    write(f, string(cur_best_reward), '\\n')\n",
    "                end\n",
    "            end\n",
    "    \n",
    "        end\n",
    "        \n",
    "    end\n",
    "        return net, cur_best_game\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GENERATION 1\n",
      "\n",
      "1. Best individuals: [36, 32, 30, 29, 29, 28, 26, 26, 25, 24, 24]\n",
      "Mean best reward: 28.09090909090909\n",
      "\n",
      " GENERATION 2\n",
      "\n",
      "2. Best individuals: [44, 40, 40, 38, 36, 36, 35, 32, 30, 29, 29, 28, 28]\n",
      "Mean best reward: 34.23076923076923\n",
      "\n",
      " GENERATION 3\n",
      "\n",
      "3. Best individuals: [44, 40, 40, 40, 38, 37, 36, 36, 36, 35, 35, 34]\n",
      "Mean best reward: 37.583333333333336\n",
      "\n",
      " GENERATION 4\n",
      "\n",
      "4. Best individuals: [44, 44, 42, 40, 40, 40, 38, 38, 37, 36, 36, 36, 36, 36]\n",
      "Mean best reward: 38.785714285714285\n",
      "\n",
      " GENERATION 5\n",
      "\n",
      "5. Best individuals: [44, 44, 42, 40, 40, 40, 38, 38, 37, 36, 36, 36, 36, 36]\n",
      "Mean best reward: 38.785714285714285\n",
      "\n",
      " GENERATION 6\n",
      "\n",
      "6. Best individuals: [44, 44, 42, 41, 40, 40, 40, 38, 38, 37, 37, 36, 36, 36, 36, 36]\n",
      "Mean best reward: 38.8125\n",
      "\n",
      " GENERATION 7\n",
      "\n",
      "7. Best individuals: [44, 44, 42, 41, 40, 40, 40, 38, 38, 37, 37, 36, 36, 36, 36, 36, 36]\n",
      "Mean best reward: 38.64705882352941\n",
      "\n",
      " GENERATION 8\n",
      "\n",
      "8. Best individuals: [48, 44, 44, 43, 42, 42, 41, 40, 40, 40, 38, 38]\n",
      "Mean best reward: 41.666666666666664\n",
      "\n",
      " GENERATION 9\n",
      "\n",
      "9. Best individuals: [48, 46, 44, 44, 43, 42, 42, 41, 40, 40, 40, 38, 38]\n",
      "Mean best reward: 42.0\n",
      "\n",
      " GENERATION 10\n",
      "\n",
      "10. Best individuals: [48, 46, 44, 44, 43, 42, 42, 41, 40, 40, 40, 40, 40]\n",
      "Mean best reward: 42.30769230769231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Chain(Dense(49 => 128, relu), Dense(128 => 64, relu), Dense(64 => 4, relu), Dense(4 => 49, Ïƒ)), [0 0 â€¦ 0 0; 0 0 â€¦ 0 0; â€¦ ; 0 1 â€¦ 0 1; 1 1 â€¦ 0 1])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sessions = 1000\n",
    "n = 7\n",
    "filename = \"7x7\"\n",
    "best_net, best_game = train(n, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
